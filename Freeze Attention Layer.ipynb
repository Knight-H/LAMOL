{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Attention](pic/attention.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing attention head <br>\n",
    "Freeze only QKV matrices?\n",
    "OR\n",
    "Also projection layer ($W_{o}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_gpt2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.configuration_gpt2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f7dd7da0ad0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class:' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_input :', grad_input[0])\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_output :', grad_output[0])\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "attn_model.attention.c_attn.register_backward_hook(printgradnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_attention_head(layer, head_indices, bias_indices=None):\n",
    "    if bias_indices is None:\n",
    "        bias_indices = head_indices\n",
    "\n",
    "    def freezing_hook_full(layer, grad_input, grad_output, weight_multiplier, bias_multiplier):\n",
    "        return (grad_input[0] * weight_multiplier,)\n",
    "\n",
    "    weight_multiplier = torch.ones(layer.weight.shape[1])\n",
    "    for head in head_indices:\n",
    "        weight_multiplier[head*64:(head+1)*64] = 0\n",
    "        weight_multiplier[head*64+768:(head+1)*64+768] = 0\n",
    "        weight_multiplier[head*64+(768*2):(head+1)*64+(768*2)] = 0\n",
    "#     weight_multiplier = weight_multiplier.view(1, -1)\n",
    "    bias_multiplier = torch.ones(layer.weight.shape[1])\n",
    "    bias_multiplier[bias_indices] = 0\n",
    "    freezing_hook = lambda layer, grad_input, grad_output: freezing_hook_full(layer, grad_input, grad_output, weight_multiplier, bias_multiplier)\n",
    "\n",
    "    layer.register_backward_hook(freezing_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.cfg = GPT2Config()\n",
    "        self.attention = Attention(nx=768,n_ctx=1024,config=self.cfg)\n",
    "        self.lmhead = nn.Linear(self.cfg.n_embd, self.cfg.vocab_size, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.attention(x)\n",
    "        return self.lmhead(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(attn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_attention_head(attn_model.attention.c_attn,[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.rand((1,16,768),dtype=torch.float)\n",
    "random_target = torch.rand((16,50257),dtype=torch.float)\n",
    "random_target = random_target.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 2304])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "model_output = attn_model(random_input)\n",
    "print(attn_model.attention.c_attn.weight.shape)\n",
    "print(attn_model.attention.c_attn.weight[:,0].shape)\n",
    "old_attn_wgt = attn_model.attention.c_attn.weight.clone().detach()\n",
    "optimizer.zero_grad()\n",
    "loss = loss_fct(model_output[0],random_target)\n",
    "attn_model.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "new_attn_wgt = attn_model.attention.c_attn.weight.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_attn_wgt[:,:64].equal(new_attn_wgt[:,:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_attn_wgt[:,64:768].equal(new_attn_wgt[:,64:768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_attn_wgt[:,768:64+768].equal(new_attn_wgt[:,768:64+768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_attn_wgt[:,768+64:128+768].equal(new_attn_wgt[:,768+64:128+768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.ones(2,3)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.],\n",
       "        [1., 0., 1.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp * torch.tensor([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
